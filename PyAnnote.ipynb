{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/dpandya/miniconda3/envs/PyAnnote/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pyannote.audio import Pipeline\n",
    "\n",
    "pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization@2.1\",\n",
    "                                    use_auth_token=\"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\")\n",
    "\n",
    "diarization = pipeline(\"audio_de_test.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['SPEAKER_02', 'SPEAKER_03', 'SPEAKER_01', 'SPEAKER_00'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get timestamps of each speaker\n",
    "speakers = [] #speaker list\n",
    "tp_list = [] #timestamp list\n",
    "sp_tp_list = dict() #all timestamps per speaker\n",
    "\n",
    "for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "    # speaker speaks between turn.start and turn.end\n",
    "    tp = (speaker, [round(turn.start, 2), round(turn.end, 2)])\n",
    "    tp_list.append(tp)\n",
    "    # print(round(turn.start, 2), round(turn.end, 2), \"duration:\", round(turn.end-turn.start, 2), speaker)\n",
    "    speakers.append(speaker)\n",
    "\n",
    "for speaker in set(speakers):\n",
    "  tp = []\n",
    "  for e in tp_list:\n",
    "    if e[0] == speaker:\n",
    "      tp.append(e[1])\n",
    "  sp_tp_list[speaker] = tp\n",
    "\n",
    "sp_tp_list.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPEAKER_01 [3.06, 15.09]\n",
      "SPEAKER_01 [19.01, 19.94]\n",
      "SPEAKER_03 [19.94, 20.68]\n",
      "SPEAKER_03 [21.52, 32.05]\n",
      "SPEAKER_02 [32.05, 34.1]\n",
      "SPEAKER_01 [34.1, 37.0]\n",
      "SPEAKER_00 [37.0, 47.58]\n",
      "SPEAKER_01 [48.07, 48.91]\n",
      "SPEAKER_00 [49.45, 51.95]\n",
      "SPEAKER_02 [51.93, 68.45]\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(speakers)):\n",
    "    speaker = speakers[i]\n",
    "    print(speaker, tp_list[i][1])\n",
    "#sp_tp_list.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-08-24 12:31:31--  https://raw.githubusercontent.com/Tttthea/speaker/main/codes/preprocessing.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5913 (5.8K) [text/plain]\n",
      "Saving to: 'preprocessing.py'\n",
      "\n",
      "preprocessing.py    100%[===================>]   5.77K  --.-KB/s    in 0s      \n",
      "\n",
      "2023-08-24 12:31:32 (65.9 MB/s) - 'preprocessing.py' saved [5913/5913]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!wget https://raw.githubusercontent.com/Tttthea/speaker/main/codes/preprocessing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import preprocessing\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "aud,sr = librosa.load('audio_de_test.wav')\n",
    "t1 = (int)(tp_list[5][1][0] * sr)\n",
    "t2 = (int)(tp_list[5][1][1] * sr)\n",
    "new_aud = aud[t1:t2]\n",
    "sf.write(file='new_audio0.wav',data= new_aud, samplerate=sr, format='wav')\n",
    "#model = pickle.load(open('model.pickle', 'rb'))\n",
    "#model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:30:28] WARNING: ../src/learner.cc:553: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[13:30:28] WARNING: ../src/learner.cc:553: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "test size: (1, 72)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "with open(\"model.pickle\", 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "df = pd.DataFrame(columns=[i for i in range(72)])\n",
    "\n",
    "line = preprocessing.feat_engineering('new_audio0.wav', False)\n",
    "preds = model.predict(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SPEAKER_01', [34.1, 37.0])\n",
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "print(tp_list[5])\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"audio.rttm\", \"w\") as rttm:\n",
    "    diarization.write_rttm(rttm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyAnnote",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
