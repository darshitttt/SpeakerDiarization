{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/dpandya/miniconda3/envs/learning/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/work/dpandya/miniconda3/envs/learning/lib/python3.10/site-packages/funasr_onnx/punc_bin.py:267: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "  def vad_mask(self, size, vad_pos, dtype=np.bool):\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'bool'.\n`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfunasr_onnx\u001b[39;00m \u001b[39mimport\u001b[39;00m Fsmn_vad\n\u001b[1;32m      3\u001b[0m model_dir \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m../FSMN-VAD/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m model \u001b[39m=\u001b[39m Fsmn_vad(model_dir, quantize\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/work/dpandya/miniconda3/envs/learning/lib/python3.10/site-packages/funasr_onnx/__init__.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mvad_bin\u001b[39;00m \u001b[39mimport\u001b[39;00m Fsmn_vad\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mvad_bin\u001b[39;00m \u001b[39mimport\u001b[39;00m Fsmn_vad_online\n\u001b[0;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpunc_bin\u001b[39;00m \u001b[39mimport\u001b[39;00m CT_Transformer\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpunc_bin\u001b[39;00m \u001b[39mimport\u001b[39;00m CT_Transformer_VadRealtime\n",
      "File \u001b[0;32m/work/dpandya/miniconda3/envs/learning/lib/python3.10/site-packages/funasr_onnx/punc_bin.py:154\u001b[0m\n\u001b[1;32m    150\u001b[0m         outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mort_infer([feats, feats_len])\n\u001b[1;32m    151\u001b[0m         \u001b[39mreturn\u001b[39;00m outputs\n\u001b[0;32m--> 154\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mCT_Transformer_VadRealtime\u001b[39;00m(CT_Transformer):\n\u001b[1;32m    155\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[39m    Author: Speech Lab of DAMO Academy, Alibaba Group\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[39m    CT-Transformer: Controllable time-delay transformer for real-time punctuation prediction and disfluency detection\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[39m    https://arxiv.org/pdf/2003.01309.pdf\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    160\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, model_dir: Union[\u001b[39mstr\u001b[39m, Path] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    161\u001b[0m                  batch_size: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m,\n\u001b[1;32m    162\u001b[0m                  device_id: Union[\u001b[39mstr\u001b[39m, \u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m-1\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    165\u001b[0m                  cache_dir: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    166\u001b[0m                  ):\n",
      "File \u001b[0;32m/work/dpandya/miniconda3/envs/learning/lib/python3.10/site-packages/funasr_onnx/punc_bin.py:267\u001b[0m, in \u001b[0;36mCT_Transformer_VadRealtime\u001b[0;34m()\u001b[0m\n\u001b[1;32m    264\u001b[0m     param_dict[cache_key] \u001b[39m=\u001b[39m cache_out\n\u001b[1;32m    265\u001b[0m     \u001b[39mreturn\u001b[39;00m sentence_out, sentence_punc_list_out, cache_out\n\u001b[0;32m--> 267\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvad_mask\u001b[39m(\u001b[39mself\u001b[39m, size, vad_pos, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39;49mbool):\n\u001b[1;32m    268\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Create mask for decoder self-attention.\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \n\u001b[1;32m    270\u001b[0m \u001b[39m    :param int size: size of mask\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[39m    :rtype: torch.Tensor (B, Lmax, Lmax)\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    275\u001b[0m     ret \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mones((size, size), dtype\u001b[39m=\u001b[39mdtype)\n",
      "File \u001b[0;32m/work/dpandya/miniconda3/envs/learning/lib/python3.10/site-packages/numpy/__init__.py:305\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    300\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    301\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIn the future `np.\u001b[39m\u001b[39m{\u001b[39;00mattr\u001b[39m}\u001b[39;00m\u001b[39m` will be defined as the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    302\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcorresponding NumPy scalar.\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFutureWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m    304\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39min\u001b[39;00m __former_attrs__:\n\u001b[0;32m--> 305\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[1;32m    307\u001b[0m \u001b[39m# Importing Tester requires importing all of UnitTest which is not a\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[39m# cheap import Since it is mainly used in test suits, we lazy import it\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[39m# here to save on the order of 10 ms of import time for most users\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[39m# The previous way Tester was imported also had a side effect of adding\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[39m# the full `numpy.testing` namespace\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtesting\u001b[39m\u001b[39m'\u001b[39m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'bool'.\n`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "from funasr_onnx import Fsmn_vad\n",
    "\n",
    "model_dir = \"../FSMN-VAD/\"\n",
    "model = Fsmn_vad(model_dir, quantize=True)\n",
    "\n",
    "wav_path = \"audio_de_test_mono.wav\"\n",
    "\n",
    "result = model(wav_path)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/dpandya/miniconda3/envs/learning/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "torchvision is not available - cannot save figures\n"
     ]
    }
   ],
   "source": [
    "import speechbrain\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "from speechbrain.pretrained import SpeakerRecognition\n",
    "from speechbrain.pretrained import VAD\n",
    "#from speechbrain.pretrained import EncoderClassifier\n",
    "\n",
    "VAD = VAD.from_hparams(source=\"speechbrain/vad-crdnn-libriparty\", savedir='pretrained_models/VAD')\n",
    "verification = SpeakerRecognition.from_hparams(source=\"speechbrain/spkrec-ecapa-voxceleb\", savedir=\"pretrained_models/spkrec-ecapa-voxceleb\")\n",
    "#classifier = EncoderClassifier.from_hparams('speechbrain/spkrec-ecapa-voxceleb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'signal, sr = torchaudio.load(audio_wav)\\nsignal.shape, sr'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_chunks_fromPath(path, c_size, stride):\n",
    "    \n",
    "    signal, sr = torchaudio.load(path)\n",
    "    chunks_tensor = VAD.create_chunks(signal, chunk_size=c_size*sr, chunk_stride=stride*sr)\n",
    "    chunk_dir = path.split('.wav')[0]\n",
    "    if not os.path.isdir(chunk_dir):\n",
    "        os.makedirs(chunk_dir)\n",
    "    #os.mkdir(chunk_dir)\n",
    "    chunk_fn_list = []\n",
    "    print(chunks_tensor.shape)\n",
    "    for i in range(0, chunks_tensor.shape[0]):\n",
    "        outfn = f'{chunk_dir}/chunk{i}.wav'\n",
    "        chunk_fn_list.append(outfn)\n",
    "        torchaudio.save(outfn, chunks_tensor[i].unsqueeze(0), sr)\n",
    "    \n",
    "    return chunk_fn_list\n",
    "\n",
    "audio_wav = '../audioData/familyDecisionVids/336.wav'\n",
    "#audio_wav = 'audio_de_test_mono.wav'\n",
    "\n",
    "'''signal, sr = torchaudio.load(audio_wav)\n",
    "signal.shape, sr'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([318, 160000])\n"
     ]
    }
   ],
   "source": [
    "aud_list = create_chunks_fromPath(audio_wav,10,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.7400, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.6100]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9400]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9000]])\n",
      "tensor([[0.0000, 7.8900],\n",
      "        [9.5900, 9.9800]])\n",
      "tensor([[0.0000, 5.7500],\n",
      "        [7.7800, 9.9800]])\n",
      "tensor([[0.6200, 3.6100],\n",
      "        [5.7200, 9.9800]])\n",
      "tensor([[0.0000, 2.0900],\n",
      "        [3.1700, 9.9800]])\n",
      "tensor([[0.9300, 9.9800]])\n",
      "tensor([[0.4100, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 8.3600],\n",
      "        [9.4400, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.8800, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 2.2500],\n",
      "        [4.6800, 9.9800]])\n",
      "tensor([[2.6000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.4600]])\n",
      "tensor([[0.0000, 9.1000]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 5.6400],\n",
      "        [6.7000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 7.9300]])\n",
      "tensor([[0.0000, 5.9700],\n",
      "        [8.2100, 9.9800]])\n",
      "tensor([[0.0000, 4.3600],\n",
      "        [6.2600, 9.9800]])\n",
      "tensor([[0.0000, 2.4600],\n",
      "        [4.2100, 9.9800]])\n",
      "tensor([[1.7500, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 8.2000]])\n",
      "tensor([[0.0000, 5.9200],\n",
      "        [9.0600, 9.9800]])\n",
      "tensor([[0.0000, 3.9500],\n",
      "        [7.0500, 9.9800]])\n",
      "tensor([[0.0000, 1.8500],\n",
      "        [5.0600, 9.8200]])\n",
      "tensor([[3.0300, 9.9800]])\n",
      "tensor([[0.9500, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[1.3900, 9.4800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 5.8600],\n",
      "        [6.8200, 9.9800]])\n",
      "tensor([[0.0000, 3.4400],\n",
      "        [4.8600, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.7400, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.4200, 9.9800]])\n",
      "tensor([[0.0000, 9.7500]])\n",
      "tensor([[0.0000, 9.9400]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0., 8.]])\n",
      "tensor([[0.2700, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[1.7300, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.2500, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.4800]])\n",
      "tensor([[0.0300, 7.4900],\n",
      "        [8.6500, 9.9800]])\n",
      "tensor([[0.0000, 4.3800],\n",
      "        [6.5700, 9.9800]])\n",
      "tensor([[0.0000, 1.9700],\n",
      "        [4.6500, 9.9800]])\n",
      "tensor([[0.0000, 1.3200],\n",
      "        [2.6100, 9.9800]])\n",
      "tensor([[0.5300, 9.9800]])\n",
      "tensor([[0.0000, 9.4300]])\n",
      "tensor([[0.0000, 7.4800]])\n",
      "tensor([[0.0000, 5.5700]])\n",
      "tensor([[0.0000, 3.3300],\n",
      "        [8.0000, 9.9800]])\n",
      "tensor([[0.0000, 1.3900],\n",
      "        [5.9600, 9.9800]])\n",
      "tensor([[3.8600, 9.9800]])\n",
      "tensor([[1.8500, 9.9800]])\n",
      "tensor([[0.0000, 7.5400]])\n",
      "tensor([[0.0000, 5.7700],\n",
      "        [8.4800, 9.9800]])\n",
      "tensor([[0.0000, 3.9100],\n",
      "        [6.4400, 9.9800]])\n",
      "tensor([[0.0000, 2.0800],\n",
      "        [3.8800, 9.9800]])\n",
      "tensor([[1.7400, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.2100, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 8.6500]])\n",
      "tensor([[0.0000, 6.9400]])\n",
      "tensor([[0.0000, 5.0300],\n",
      "        [7.9600, 9.9800]])\n",
      "tensor([[0.0000, 2.2700],\n",
      "        [5.8000, 9.9800]])\n",
      "tensor([[3.7600, 9.9800]])\n",
      "tensor([[1.7400, 8.7300]])\n",
      "tensor([[0.0000, 6.6600]])\n",
      "tensor([[0.0000, 4.7500],\n",
      "        [8.8700, 9.9800]])\n",
      "tensor([[0.0000, 2.7600],\n",
      "        [6.7400, 9.9800]])\n",
      "tensor([[0.0000, 1.1500],\n",
      "        [3.5400, 9.9800]])\n",
      "tensor([[1.5400, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.1400]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 8.3900]])\n",
      "tensor([[0.0000, 6.0400],\n",
      "        [7.7500, 9.9800]])\n",
      "tensor([[0.0000, 4.0800],\n",
      "        [5.7000, 9.9800]])\n",
      "tensor([[0.0000, 2.1000],\n",
      "        [3.8800, 8.1700]])\n",
      "tensor([[1.7000, 6.1700],\n",
      "        [9.4200, 9.9800]])\n",
      "tensor([[0.0000, 4.1100],\n",
      "        [7.4000, 9.9800]])\n",
      "tensor([[0.0000, 1.9500],\n",
      "        [5.4700, 9.9800]])\n",
      "tensor([[3.2800, 9.9800]])\n",
      "tensor([[1.7400, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.6100]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9400]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9000]])\n",
      "tensor([[0.0000, 7.8900],\n",
      "        [9.5900, 9.9800]])\n",
      "tensor([[0.0000, 5.7500],\n",
      "        [7.7800, 9.9800]])\n",
      "tensor([[0.6200, 3.6100],\n",
      "        [5.7200, 9.9800]])\n",
      "tensor([[0.0000, 2.0900],\n",
      "        [3.1700, 9.9800]])\n",
      "tensor([[0.9300, 9.9800]])\n",
      "tensor([[0.4100, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 8.3600],\n",
      "        [9.4400, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.8800, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 2.2500],\n",
      "        [4.6800, 9.9800]])\n",
      "tensor([[2.6000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.4600]])\n",
      "tensor([[0.0000, 9.1000]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 5.6400],\n",
      "        [6.7000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 7.9300]])\n",
      "tensor([[0.0000, 5.9700],\n",
      "        [8.2100, 9.9800]])\n",
      "tensor([[0.0000, 4.3600],\n",
      "        [6.2600, 9.9800]])\n",
      "tensor([[0.0000, 2.4600],\n",
      "        [4.2100, 9.9800]])\n",
      "tensor([[1.7500, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 8.2000]])\n",
      "tensor([[0.0000, 5.9200],\n",
      "        [9.0600, 9.9800]])\n",
      "tensor([[0.0000, 3.9500],\n",
      "        [7.0500, 9.9800]])\n",
      "tensor([[0.0000, 1.8500],\n",
      "        [5.0600, 9.8200]])\n",
      "tensor([[3.0300, 9.9800]])\n",
      "tensor([[0.9500, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[1.3900, 9.4800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 5.8600],\n",
      "        [6.8200, 9.9800]])\n",
      "tensor([[0.0000, 3.4400],\n",
      "        [4.8600, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.7400, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.4200, 9.9800]])\n",
      "tensor([[0.0000, 9.7500]])\n",
      "tensor([[0.0000, 9.9400]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0., 8.]])\n",
      "tensor([[0.2700, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[1.7300, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.2500, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.4800]])\n",
      "tensor([[0.0300, 7.4900],\n",
      "        [8.6500, 9.9800]])\n",
      "tensor([[0.0000, 4.3800],\n",
      "        [6.5700, 9.9800]])\n",
      "tensor([[0.0000, 1.9700],\n",
      "        [4.6500, 9.9800]])\n",
      "tensor([[0.0000, 1.3200],\n",
      "        [2.6100, 9.9800]])\n",
      "tensor([[0.5300, 9.9800]])\n",
      "tensor([[0.0000, 9.4300]])\n",
      "tensor([[0.0000, 7.4800]])\n",
      "tensor([[0.0000, 5.5700]])\n",
      "tensor([[0.0000, 3.3300],\n",
      "        [8.0000, 9.9800]])\n",
      "tensor([[0.0000, 1.3900],\n",
      "        [5.9600, 9.9800]])\n",
      "tensor([[3.8600, 9.9800]])\n",
      "tensor([[1.8500, 9.9800]])\n",
      "tensor([[0.0000, 7.5400]])\n",
      "tensor([[0.0000, 5.7700],\n",
      "        [8.4800, 9.9800]])\n",
      "tensor([[0.0000, 3.9100],\n",
      "        [6.4400, 9.9800]])\n",
      "tensor([[0.0000, 2.0800],\n",
      "        [3.8800, 9.9800]])\n",
      "tensor([[1.7400, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.2100, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 8.6500]])\n",
      "tensor([[0.0000, 6.9400]])\n",
      "tensor([[0.0000, 5.0300],\n",
      "        [7.9600, 9.9800]])\n",
      "tensor([[0.0000, 2.2700],\n",
      "        [5.8000, 9.9800]])\n",
      "tensor([[3.7600, 9.9800]])\n",
      "tensor([[1.7400, 8.7300]])\n",
      "tensor([[0.0000, 6.6600]])\n",
      "tensor([[0.0000, 4.7500],\n",
      "        [8.8700, 9.9800]])\n",
      "tensor([[0.0000, 2.7600],\n",
      "        [6.7400, 9.9800]])\n",
      "tensor([[0.0000, 1.1500],\n",
      "        [3.5400, 9.9800]])\n",
      "tensor([[1.5400, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.1400]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 9.9800]])\n",
      "tensor([[0.0000, 8.3900]])\n",
      "tensor([[0.0000, 6.0400],\n",
      "        [7.7500, 9.9800]])\n",
      "tensor([[0.0000, 4.0800],\n",
      "        [5.7000, 9.9800]])\n",
      "tensor([[0.0000, 2.1000],\n",
      "        [3.8800, 8.1700]])\n",
      "tensor([[1.7000, 6.1700],\n",
      "        [9.4200, 9.9800]])\n",
      "tensor([[0.0000, 4.1100],\n",
      "        [7.4000, 9.9800]])\n",
      "tensor([[0.0000, 1.9500],\n",
      "        [5.4700, 9.9800]])\n",
      "tensor([[3.2800, 9.9800]])\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(aud_list)):\n",
    "    print(VAD.get_speech_segments(aud_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#segment_list = VAD.get_speech_segments('../audioData/familyDecisionVids/336.wav')\n",
    "chunks_tensor = VAD.create_chunks(signal, chunk_size=10*sr, chunk_stride=2*sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio_de_test_mono_chunk0.wav\n",
      "audio_de_test_mono_chunk1.wav\n",
      "audio_de_test_mono_chunk2.wav\n",
      "audio_de_test_mono_chunk3.wav\n",
      "audio_de_test_mono_chunk4.wav\n",
      "audio_de_test_mono_chunk5.wav\n",
      "audio_de_test_mono_chunk6.wav\n",
      "audio_de_test_mono_chunk7.wav\n",
      "audio_de_test_mono_chunk8.wav\n",
      "audio_de_test_mono_chunk9.wav\n",
      "audio_de_test_mono_chunk10.wav\n",
      "audio_de_test_mono_chunk11.wav\n",
      "audio_de_test_mono_chunk12.wav\n",
      "audio_de_test_mono_chunk13.wav\n",
      "audio_de_test_mono_chunk14.wav\n",
      "audio_de_test_mono_chunk15.wav\n",
      "audio_de_test_mono_chunk16.wav\n",
      "audio_de_test_mono_chunk17.wav\n",
      "audio_de_test_mono_chunk18.wav\n",
      "audio_de_test_mono_chunk19.wav\n",
      "audio_de_test_mono_chunk20.wav\n",
      "audio_de_test_mono_chunk21.wav\n",
      "audio_de_test_mono_chunk22.wav\n",
      "audio_de_test_mono_chunk23.wav\n",
      "audio_de_test_mono_chunk24.wav\n",
      "audio_de_test_mono_chunk25.wav\n",
      "audio_de_test_mono_chunk26.wav\n",
      "audio_de_test_mono_chunk27.wav\n",
      "audio_de_test_mono_chunk28.wav\n",
      "audio_de_test_mono_chunk29.wav\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 30 is out of bounds for dimension 0 with size 30",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, chunks_tensor\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m      4\u001b[0m     out_fn \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00msss\u001b[39m}\u001b[39;00m\u001b[39m_chunk\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m.wav\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 5\u001b[0m     torchaudio\u001b[39m.\u001b[39msave(out_fn,chunks_tensor[i]\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m),\u001b[39m16000\u001b[39m)\n\u001b[1;32m      6\u001b[0m     \u001b[39mprint\u001b[39m(out_fn)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 30 is out of bounds for dimension 0 with size 30"
     ]
    }
   ],
   "source": [
    "sss = audio_wav.split('.')[0]\n",
    "\n",
    "for i in range(0, chunks_tensor.shape[1]-1):\n",
    "    out_fn = f'{sss}_chunk{i}.wav'\n",
    "    torchaudio.save(out_fn,chunks_tensor[i].unsqueeze(0),16000)\n",
    "    print(out_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/snakers4/silero-vad/zipball/master\" to /home/dpandya/.cache/torch/hub/master.zip\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "USE_ONNX = False\n",
    "\n",
    "model, utils = torch.hub.load(repo_or_dir='snakers4/silero-vad',\n",
    "                              model='silero_vad',\n",
    "                              force_reload=True,\n",
    "                              onnx=USE_ONNX)\n",
    "\n",
    "(get_speech_timestamps,\n",
    " save_audio,\n",
    " read_audio,\n",
    " VADIterator,\n",
    " collect_chunks) = utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'start': 38944, 'end': 49632}, {'start': 55328, 'end': 91616}, {'start': 99872, 'end': 139232}, {'start': 143392, 'end': 160000}]\n",
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[90], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(aud_list)):\n\u001b[1;32m      2\u001b[0m     wav \u001b[39m=\u001b[39m read_audio(aud_list[i], sampling_rate\u001b[39m=\u001b[39m\u001b[39m16000\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     speech_timestamps \u001b[39m=\u001b[39m get_speech_timestamps(wav, model, sampling_rate\u001b[39m=\u001b[39;49m\u001b[39m16000\u001b[39;49m)\n\u001b[1;32m      4\u001b[0m     \u001b[39mprint\u001b[39m(speech_timestamps)\n\u001b[1;32m      5\u001b[0m     \u001b[39mprint\u001b[39m(i)\n",
      "File \u001b[0;32m~/.cache/torch/hub/snakers4_silero-vad_master/utils_vad.py:267\u001b[0m, in \u001b[0;36mget_speech_timestamps\u001b[0;34m(audio, model, threshold, sampling_rate, min_speech_duration_ms, max_speech_duration_s, min_silence_duration_ms, window_size_samples, speech_pad_ms, return_seconds, visualize_probs, progress_tracking_callback)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(chunk) \u001b[39m<\u001b[39m window_size_samples:\n\u001b[1;32m    266\u001b[0m     chunk \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mpad(chunk, (\u001b[39m0\u001b[39m, \u001b[39mint\u001b[39m(window_size_samples \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(chunk))))\n\u001b[0;32m--> 267\u001b[0m speech_prob \u001b[39m=\u001b[39m model(chunk, sampling_rate)\u001b[39m.\u001b[39mitem()\n\u001b[1;32m    268\u001b[0m speech_probs\u001b[39m.\u001b[39mappend(speech_prob)\n\u001b[1;32m    269\u001b[0m \u001b[39m# caculate progress and seng it to callback function\u001b[39;00m\n",
      "File \u001b[0;32m/work/dpandya/miniconda3/envs/learning/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(0, len(aud_list)):\n",
    "    wav = read_audio(aud_list[i], sampling_rate=16000)\n",
    "    speech_timestamps = get_speech_timestamps(wav, model, sampling_rate=16000)\n",
    "    print(speech_timestamps)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[88], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m wav \u001b[39m=\u001b[39m read_audio(\u001b[39m'\u001b[39m\u001b[39maudio_de_test_mono.wav\u001b[39m\u001b[39m'\u001b[39m, sampling_rate\u001b[39m=\u001b[39m\u001b[39m16000\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[39m# get speech timestamps from full audio file\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m speech_timestamps \u001b[39m=\u001b[39m get_speech_timestamps(wav, model, sampling_rate\u001b[39m=\u001b[39;49m\u001b[39m16000\u001b[39;49m)\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(speech_timestamps)\n",
      "File \u001b[0;32m~/.cache/torch/hub/snakers4_silero-vad_master/utils_vad.py:267\u001b[0m, in \u001b[0;36mget_speech_timestamps\u001b[0;34m(audio, model, threshold, sampling_rate, min_speech_duration_ms, max_speech_duration_s, min_silence_duration_ms, window_size_samples, speech_pad_ms, return_seconds, visualize_probs, progress_tracking_callback)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(chunk) \u001b[39m<\u001b[39m window_size_samples:\n\u001b[1;32m    266\u001b[0m     chunk \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mpad(chunk, (\u001b[39m0\u001b[39m, \u001b[39mint\u001b[39m(window_size_samples \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(chunk))))\n\u001b[0;32m--> 267\u001b[0m speech_prob \u001b[39m=\u001b[39m model(chunk, sampling_rate)\u001b[39m.\u001b[39mitem()\n\u001b[1;32m    268\u001b[0m speech_probs\u001b[39m.\u001b[39mappend(speech_prob)\n\u001b[1;32m    269\u001b[0m \u001b[39m# caculate progress and seng it to callback function\u001b[39;00m\n",
      "File \u001b[0;32m/work/dpandya/miniconda3/envs/learning/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "wav = read_audio('audio_de_test_mono.wav', sampling_rate=16000)\n",
    "# get speech timestamps from full audio file\n",
    "speech_timestamps = get_speech_timestamps(wav, model, sampling_rate=16000)\n",
    "print(speech_timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_list = VAD.get_speech_segments('/work/dpandya/giggityGit/SpeakerDiarization/audio_de_test_mono_chunk0.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.8700, 9.9800]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embeddings = classifier.encode_batch(signal)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
